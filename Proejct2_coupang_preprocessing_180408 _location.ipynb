{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import sklearn as sk\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블 현황 파악을 위한 함수 \n",
    "def summary_table(table):\n",
    "    df = pd.DataFrame()\n",
    "    for i in table.columns:\n",
    "        name = i\n",
    "        dtype = table[i].dtype.name\n",
    "        null = table[i].isnull().sum()\n",
    "        act = table.shape[0] - null\n",
    "        unique = len(table[i].unique())\n",
    "        data = {'name': name, 'dtype': dtype, 'null': null, 'act': act, 'unique': unique}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기: 일본어는 영어로 번역, 지역에 Prefecture가 붙은 지명은 Prefecture 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "detail_train = pd.read_csv('coupon_data_project2/coupon_detail_train_translated_en.csv', \n",
    "                           parse_dates=['I_DATE'])  # 쿠폰 구매 내역\n",
    "\n",
    "visit_train = pd.read_csv('coupon_data_project2/coupon_visit_train.csv',\n",
    "                          parse_dates=['I_DATE']) # 쿠폰 조회 내역\n",
    "\n",
    "area_train = pd.read_csv('coupon_data_project2/coupon_area_train_translated_en.csv') # 쿠폰 사용 가능 지역\n",
    "coupon_list_train = pd.read_csv('coupon_data_project2/coupon_list_train_translated_en.csv', \n",
    "                                parse_dates=['DISPFROM', 'DISPEND', 'VALIDFROM', 'VALIDEND']) # 쿠폰 리스트(train)\n",
    "\n",
    "# base data\n",
    "location = pd.read_csv('coupon_data_project2/train_location.csv') # 지역 위치 정보(위도/경도)\n",
    "user_list = pd.read_csv('coupon_data_project2/user_list_translated_en.csv', \n",
    "                        parse_dates=['WITHDRAW_DATE', 'REG_DATE']) # user 정보\n",
    "\n",
    "# test data\n",
    "area_test = pd.read_csv('coupon_data_project2/test_location.csv') # 쿠폰 사용 가능 지역\n",
    "coupon_list_test = pd.read_csv('coupon_data_project2/coupon_list_test_translated_en.csv',\n",
    "                               parse_dates=['DISPFROM', 'DISPEND', 'VALIDFROM', 'VALIDEND']) # 쿠폰 리스트\n",
    "\n",
    "# submisiion\n",
    "submission = pd.read_csv('coupon_data_project2/sample_submission.csv') # 제출 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "## A. Preprocessing\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-1. detail_train\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>null</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtype</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>datetime64[ns]</th>\n",
       "      <th>I_DATE</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int64</th>\n",
       "      <th>ITEM_COUNT</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">object</th>\n",
       "      <th>COUPON_ID_hash</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURCHASEID_hash</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMALL_AREA_NAME</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID_hash</th>\n",
       "      <td>168996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22782.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     act  null    unique\n",
       "dtype          name                                     \n",
       "datetime64[ns] I_DATE           168996.0   0.0  130309.0\n",
       "int64          ITEM_COUNT       168996.0   0.0      32.0\n",
       "object         COUPON_ID_hash   168996.0   0.0   19368.0\n",
       "               PURCHASEID_hash  168996.0   0.0  168996.0\n",
       "               SMALL_AREA_NAME  168996.0   0.0      55.0\n",
       "               USER_ID_hash     168996.0   0.0   22782.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table(detail_train).pivot_table(index = ['dtype', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 신규 columns 생성\n",
    "\n",
    "1-1) merge 후 구매 구분을 위한 PURCHASE_FLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_train['PURCHASE_FLG'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) column명 변경\n",
    "\n",
    "2-1) I_DATE -> purchase_date: merge 후 구매일자 구분을 위함\n",
    "\n",
    "2-2) SMALL_AREA_NAME: coupon list의 지역(판매 spot)과 구분하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_train.rename(columns = {'I_DATE': 'purchase_date'}, inplace=True)\n",
    "detail_train.rename(columns = {'SMALL_AREA_NAME': 'resid_small'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) drop: ITEM_COUNT는 활용여부 판단후 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_train.drop(labels = ['ITEM_COUNT'], axis=1, inplace=True)\n",
    "detail_train.drop(labels = ['PURCHASEID_hash'], axis=1, inplace=True)\n",
    "detail_train.drop(labels = ['resid_small'], axis=1, inplace=True)\n",
    "# detail_train.drop(labels = ['purchase_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2. visit_train\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table(visit_train).pivot_table(index = ['dtype', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 신규 column 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train['VIEW'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) column명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train.rename(columns = {'I_DATE': 'VIEW_DATE'}, inplace=True)\n",
    "visit_train.rename(columns = {'VIEW_COUPON_ID_hash': 'COUPON_ID_hash'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train.drop(labels = ['PAGE_SERIAL'], axis=1, inplace=True) # PAGE_SERIAL에 따라 의미가 있으나 test set에 반영 불가\n",
    "visit_train.drop(labels = ['REFERRER_hash'], axis=1, inplace=True) \n",
    "visit_train.drop(labels = ['SESSION_ID_hash'], axis=1, inplace=True) \n",
    "visit_train.drop(labels = ['PURCHASEID_hash'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-3. Coupon_list\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table(coupon_list_train).pivot_table(index = ['dtype', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 전처리 일관성을 유지를 위한 coupon_list merge(311~ train임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_list = pd.merge(coupon_list_test, coupon_list_train, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_list_test.shape, coupon_list_train.shape, coupon_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 신규 columns 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캡슐과 장르 통합 및 명칭 변경\n",
    "coupon_list['Case'] = coupon_list['CAPSULE_TEXT'] + coupon_list['GENRE_NAME']\n",
    "coupon_list['Case'] = coupon_list['Case'].apply(lambda x: \"HOTEL\" if x == 'Guest houseHotel and Japanese hotel' \n",
    "                          or x == 'HotelHotel and Japanese hotel'\n",
    "                          or x == 'Japanese hotelHotel and Japanese hotel'\n",
    "                          or x == 'Japanse guest houseHotel and Japanese hotel'\n",
    "                          or x == 'LodgeHotel and Japanese hotel'\n",
    "                          or x == 'Public hotelHotel and Japanese hotel'\n",
    "                          or x == 'Resort innHotel and Japanese hotel'\n",
    "                          or x == 'Vacation rentalHotel and Japanese hotel'\n",
    "                          else \"NAIL\" if x == 'Nail and eye salonNail and eye salon'\n",
    "                          else \"HAIR\" if x == 'Hair salonHair salon'\n",
    "                          else \"FOOD\" if x == 'FoodFood'  # FOOD\n",
    "                          else \"SPA\" if x == 'SpaSpa'  # SPA\n",
    "                          else \"BEAUTY\" if x == 'BeautyBeauty'\n",
    "                          else \"CLASS\" if x == 'ClassLesson'\n",
    "                          else \"CORRESPONDENCE\" if x == 'Correspondence courseLessonClassLesson'\n",
    "                          else \"DELIVERY\" if x == 'Delivery serviceDelivery service'\n",
    "                          else \"EVENT\" if x == 'EventOther coupon'\n",
    "                          else \"GIFT\" if x == 'Gift cardGift card'\n",
    "                          else \"HEALTH\" if x == 'Health and medicalHealth and medical'\n",
    "                          else \"LEISURE\" if x == 'LeisureLeisure'  # LEISURE\n",
    "                          else \"LESSON\" if x == 'LessonLesson'\n",
    "                          else \"OTHER\" if x == 'OtherOther coupon'\n",
    "                          else \"RELAXATION\" if x == 'RelaxationRelaxation'\n",
    "                          else \"WEB\" if x == 'Web serviceOther coupon'\n",
    "                          else 'OTHER'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실판매가 게산\n",
    "coupon_list['Price'] = coupon_list['CATALOG_PRICE'] + coupon_list['DISCOUNT_PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실판매가 정규화\n",
    "coupon_list[\"lnDPRICE\"] = np.log1p(coupon_list[\"Price\"])\n",
    "coupon_list[\"mDPRICE\"] = coupon_list.groupby(\"Case\")[\"lnDPRICE\"].transform(np.mean)\n",
    "coupon_list[\"sDPRICE\"] = coupon_list.groupby(\"Case\")[\"lnDPRICE\"].transform(np.std)\n",
    "coupon_list[\"zprice\"] = (coupon_list[\"lnDPRICE\"] - coupon_list[\"mDPRICE\"]) / coupon_list[\"sDPRICE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) column명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역명 변경\n",
    "coupon_list.rename(columns = {\"LARGE_AREA_NAME\": \"spot_large\", \n",
    "                              \"ken_name\": \"spot_pref\", \n",
    "                              \"SMALL_AREA_NAME\": \"spot_small\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Null 값 및 오류 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usable: nan -> 1, 2 -> 0\n",
    "coupon_list['USABLE_DATE_MON'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_TUE'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_WED'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_THU'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_FRI'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_SAT'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_SUN'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_HOLIDAY'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)\n",
    "coupon_list['USABLE_DATE_BEFORE_HOLIDAY'].replace([0,2,1,np.nan],[0,0,1,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupon_list.drop(labels = ['CAPSULE_TEXT'], axis=1, inplace=True )\n",
    "# coupon_list.drop(labels = ['GENRE_NAME'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['CATALOG_PRICE'], axis=1, inplace=True )\n",
    "# coupon_list.drop(labels = ['DISCOUNT_PRICE'], axis=1, inplace=True )\n",
    "# coupon_list.drop(labels = ['DISPFROM'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['DISPEND'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['VALIDFROM'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['VALIDEND'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['lnDPRICE'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['mDPRICE'], axis=1, inplace=True )\n",
    "coupon_list.drop(labels = ['sDPRICE'], axis=1, inplace=True )\n",
    "# coupon_list.drop(labels = ['Price'], axis=1, inplace=True )\n",
    "# coupon_list.drop(labels = ['spot_pref'], axis=1, inplace=True )  # 판단이슈 \n",
    "coupon_list.drop(labels = ['spot_small'], axis=1, inplace=True ) # 판단이슈 \n",
    "coupon_list.drop(labels = ['spot_large'], axis=1, inplace=True ) # 판단이슈 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) train & test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set과 test set을 다시 분리\n",
    "coupon_list_train = coupon_list[311:]\n",
    "coupon_list_test = coupon_list[:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. User_list\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table(user_list).pivot_table(index = ['dtype', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) column명 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list.rename(columns = {'PREF_NAME': 'user_pref'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) SEX_ID 0,1 로 변경(f: 0, m: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEX_ID: f는 0으로 M은 1로\n",
    "user_list['SEX_ID'] = user_list['SEX_ID'].apply(lambda x: 0 if x == 'f' else 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REG_DATE , WITHDRAW_DATE 삭제\n",
    "user_list.drop(labels = ['REG_DATE'], axis=1, inplace=True)\n",
    "user_list.drop(labels = ['WITHDRAW_DATE'], axis=1, inplace=True)\n",
    "# user_list.drop(labels = ['user_pref'], axis=1, inplace=True)  # 판단 이슈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5. train set 구성\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) visit_train & detail_train -> train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.merge(visit_train, detail_train, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) train & coupon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, coupon_list, how='left', on='COUPON_ID_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) train & user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, user_list, how='left', on='USER_ID_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) train & location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['key'] = train['COUPON_ID_hash']+ train['USER_ID_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location['key'] = location['COUPON_ID_hash'] + location['USER_ID_hash'] \n",
    "location.drop_duplicates(['key'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(2, 'distance', train['key'].map(location.set_index('key')['distance']))\n",
    "train.insert(2, 'PREF_in', train['key'].map(location.set_index('key')['PREF_in']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(labels=['key'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = train[['PREF_in','distance','user_pref','spot_pref']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[~aa['distance'].isnull()][aa['spot_pref'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) train 현황 점검 및 NaN값 처리\n",
    "\n",
    "4-1) null 이 315,301개인 것들은 기초정보(coupon_list(test 포함)에 없는 것들이므로 제외 -> zprice 기준으로 처리\n",
    "\n",
    "4-2) VALIDPERIOD(null: 773,492)은 무제한이라는 의미에서 10,000으로 처리\n",
    "\n",
    "4-3) user_pref(null: 488,972) 을 NN 으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 이 315,301개인 것들은 기초정보(coupon_list(test 포함)에 없는 것들이므로 제외 -> zprice 기준으로 처리\n",
    "train = train[train['zprice'] >= -100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['VALIDPERIOD'] = train['VALIDPERIOD'].fillna(180)\n",
    "train['user_pref'] = train['user_pref'].fillna('NN')\n",
    "train['VIEW'] = train['VIEW'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['distance'] = train['distance'].fillna(train['distance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table(train).sort_values(by='unique', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 생성 -> EDA 과정에서 추가되는 편수를 같이 적용해주기 위해 test 를 먼저 불러왔음\n",
    "coupon_list_test['A'] = 1\n",
    "user_list['A'] = 1\n",
    "test = pd.merge(coupon_list_test, user_list, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### user_pref & spot_pref가 같은 경우 view 대비 buy 확률이 높다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot_table(index = ['Case', 'user_pref', 'spot_pref'], values = ['VIEW', 'PURCHASE_FLG'], aggfunc='sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['same_area'] = np.where(df['user_pref'] == df['spot_pref'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot_table(index = 'same_area', values = ['VIEW', 'PURCHASE_FLG'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['%buy'] = df['PURCHASE_FLG'] / df['VIEW'] * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_area(user, spot):\n",
    "    if user == spot : return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 same_area 추가\n",
    "train['same_area'] = list(map(same_area, train.user_pref, train.spot_pref))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set에 same_arae 추가\n",
    "test['same_area'] = list(map(same_area, test.user_pref, test.spot_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['PREF_in','distance','user_pref','spot_pref']][[df['distance']==237.740409].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pref_in = pd.pivot_table(df, values='USER_ID_hash', index=['PREF_in','PURCHASE_FLG'],aggfunc=np.size)\n",
    "table_pref_in.rename(columns={'PURCHASE_FLG', 'p'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pref_in.rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case별 판매현황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case = df.pivot_table(index = ['USER_ID_hash'], values = ['PURCHASE_FLG'],\n",
    "                         columns = ['Case'], aggfunc = np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case\n",
    "df_Case.columns = [c[1] if c[1] else c[0] for c in df_Case.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case = df_Case.reset_index()\n",
    "df_Case.fillna(0, inplace=True)\n",
    "df_Case[:2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref = df.pivot_table(index = ['USER_ID_hash'], values = ['PURCHASE_FLG'],\n",
    "                         columns = ['user_pref'], aggfunc = np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref.columns = [c[1] if c[1] else c[0] for c in df_pref.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref = df_pref.reset_index()\n",
    "df_pref.fillna(0, inplace=True)\n",
    "df_pref[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, df_Case, how='left', on='USER_ID_hash')\n",
    "train = pd.merge(train, df_pref, how='left', on ='USER_ID_hash')\n",
    "\n",
    "test = pd.merge(test, df_Case, how='left', on='USER_ID_hash')\n",
    "test = pd.merge(test, df_pref, how='left', on='USER_ID_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기 이후로는 하지 않기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Test'] = df['VIEW_DATE'] - df['DISPFROM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Test'] = df['Test'].astype('timedelta64[s]')/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Test'] = df['Test'].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pref_disp = df.pivot_table(index = ['USER_ID_hash'], values = ['Test'],\n",
    "                         columns = ['user_pref'], aggfunc = np.mean)\n",
    "df_pref_disp.columns = [c[1] if c[1] else c[0] for c in df_pref_disp.columns.tolist()]\n",
    "df_pref_disp = df_pref_disp.reset_index()\n",
    "df_pref_disp.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case_disp = df.pivot_table(index = ['USER_ID_hash'], values = ['Test'],\n",
    "                         columns = ['Case'], aggfunc = np.mean)\n",
    "df_Case_disp.columns = [c[1] if c[1] else c[0] for c in df_Case_disp.columns.tolist()]\n",
    "df_Case_disp = df_Case_disp.reset_index()\n",
    "df_Case_disp.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, df_Case_disp, how='left', on='USER_ID_hash')\n",
    "train = pd.merge(train, df_pref_disp, how='left', on ='USER_ID_hash')\n",
    "\n",
    "test = pd.merge(test, df_Case_disp, how='left', on='USER_ID_hash')\n",
    "test = pd.merge(test, df_pref_disp, how='left', on='USER_ID_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "df_pref_view = df.pivot_table(index = ['USER_ID_hash'], values = ['VIEW'],\n",
    "                             columns= ['user_pref'], aggfunc = np.mean) \n",
    "df_pref_view.columns = [c[1] if c[1] else c[0] for c in df_pref_view.columns.tolist()]\n",
    "df_pref_view = df_pref_view.reset_index()\n",
    "df_pref_view.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Case_view = df.pivot_table(index = ['USER_ID_hash'], values = ['VIEW'],\n",
    "                             columns= ['Case'], aggfunc = np.mean) \n",
    "df_Case_view.columns = [c[1] if c[1] else c[0] for c in df_Case_view.columns.tolist()]\n",
    "df_Case_view = df_Case_view.reset_index()\n",
    "df_Case_view.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, df_Case_view, how='left', on='USER_ID_hash')\n",
    "train = pd.merge(train, df_pref_view, how='left', on ='USER_ID_hash')\n",
    "\n",
    "test = pd.merge(test, df_Case_view, how='left', on='USER_ID_hash')\n",
    "test = pd.merge(test, df_pref_view, how='left', on='USER_ID_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "## B. 모델링\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. 데이터 생성\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) dummy list 생성(train & test의 일관성을 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_dummy = ['Case']\n",
    "# ls_dummy = ['user_pref', 'spot_small', 'spot_pref', 'spot_large', 'Case']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) train data dummy 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.get_dummies(train, columns = ls_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) test data 생성 -> 아래 로케이션 부분은 슬랙에서설명한 부분 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_test = pd.read_csv('coupon_data_project2/test_location3.csv') # 쿠폰 사용 가능 지역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_test 삽입\n",
    "test['key'] = test['COUPON_ID_hash'] + test['USER_ID_hash'] \n",
    "area_test['key'] = area_test['COUPON_ID_hash'] + area_test['USER_ID_hash'] \n",
    "test.insert(2, 'distance', test['key'].map(area_test.set_index('key')['distance']))\n",
    "test.insert(2, 'PREF_in', test['key'].map(area_test.set_index('key')['PREF_in']))\n",
    "test.drop(labels = ['key'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = test[['distance', 'PREF_in','spot_pref', 'user_pref']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz.distance.isnull().sum() / len(zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zz[zz['user_pref']==zz['spot_pref']]['distance'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) test data dummy처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.get_dummies(test, columns = ls_dummy)\n",
    "test.drop(labels = ['A'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5)  test & train set columns 비교 -> 지역이 문제임. 지역은 개인 판단하에 위에 drop부분에서 삭제해주시길\n",
    "\n",
    "5-1) PURCHASE_FLG: train의 y값으로 활용될 것임\n",
    "\n",
    "5-2) VIEW_DATE: 향후 활용 가능성이 있음. 우선은 mod_ls에서 걸러짐.\n",
    "\n",
    "5-3) VIEW: 향후 활용 가능성 있음(가중치 넣는 식). 우선은 mod_ls에서 걸러짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_not_test = [i for i in train.columns if i not in test.columns]\n",
    "compare_not_train = [i for i in test.columns if i not in train.columns]\n",
    "print('only_train: {}  \\n'.format(compare_not_test))\n",
    "print('only_test: {}'.format(compare_not_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. train data set\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_removed_train = {'PURCHASE_FLG', 'USER_ID_hash','COUPON_ID_hash', \"VIEW\", 'purchase_date', 'spot_pref', \n",
    "                       'user_pref', 'VIEW_DATE', 'DISPFROM', 'GENRE_NAME', 'CAPSULE_TEXT', 'Case'}\n",
    "ls_train = [i for i in list(train.columns) if i not in to_be_removed_train]\n",
    "X_train = train.filter(ls_train)\n",
    "y_train = train.PURCHASE_FLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. 모델링: xgboost\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import clone\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) train 에 활용할 컬럼 선정(test 컬럼과 일치시킴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ls = [i for i in X_train.columns if i in test.columns]\n",
    "X_train = train.filter(mod_ls)\n",
    "y_train = train.PURCHASE_FLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) parameter 지정(parameter는 우수사례 벤치마킹, 논리 및 개선여부 검토해봐야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgboost.XGBClassifier(n_estimators=300, max_depth=3,\n",
    "                                 objective = 'reg:logistic',\n",
    "                                 subsample= 0.85,\n",
    "                                 colsample_bytree=0.8,\n",
    "                                 random_state=12345,\n",
    "                                 min_child_weight=1,\n",
    "                                 learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) predict 후 sum을통해 1이 몇개인지 확인 -> 할때마다 0이 나옴 .. 아래 확률로 접근해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_xgb = model_xgb.predict(test.filter(mod_ls))\n",
    "y_pred_xgb.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) proba를 생성해서 test set과 merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_proba = model_xgb.predict_proba(test.filter(mod_ls))\n",
    "df_y_hat_proba= pd.DataFrame(y_hat_proba, columns=['n','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xgb = test.filter(['USER_ID_hash', 'COUPON_ID_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proba_df = pd.concat([test_xgb, pd.DataFrame(df_y_hat_proba)],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 기준을 잡기 위해 확률의 평균을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_proba_df.y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 모델 개선 및 현황 파악을 위한 feature importance 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_xgb.feature_importances_\n",
    "df_imp = pd.DataFrame()\n",
    "for i, j in zip(mod_ls, list(importances)):\n",
    "    data = {'columns': i, 'importance': np.round(j*100,1)} \n",
    "    df_imp = df_imp.append(data, ignore_index=True)\n",
    "\n",
    "df_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) 확률을 선정 -> 3번의 기준으로 어림잡아 선정 -> 최종 제출시에는 각 유저별 상위 10개로 지정하는게 좋겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_proba_df2 = result_proba_df[result_proba_df['y']>0.08].sort_values(by='y', ascending=False)\n",
    "result_proba_df2 = result_proba_df.sort_values(by=['USER_ID_hash','y'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) 제출양식에 맞춰 lookup_table을 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table = result_proba_df2.groupby('USER_ID_hash').apply(lambda x: list(x.COUPON_ID_hash)[:10])\n",
    "lookup_table = pd.DataFrame(lookup_table, columns = ['COUPON_ID_hash']).reset_index()\n",
    "lookup_table\n",
    "\n",
    "lookup_table.rename(columns={'COUPON_ID_hash':'PURCHASED_COUPONS'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) 매칭 및 양식에 맞춘 마무리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.insert(2, 'COUPON', submission['USER_ID_hash'].map(lookup_table.set_index('USER_ID_hash')['PURCHASED_COUPONS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop('PURCHASED_COUPONS', axis=1, inplace=True)\n",
    "submission.rename(columns={'COUPON':'PURCHASED_COUPONS'}, inplace=True)\n",
    "\n",
    "submission['PURCHASED_COUPONS'] = submission['PURCHASED_COUPONS'].astype('str')\n",
    "submission['PURCHASED_COUPONS'] = submission['PURCHASED_COUPONS'].apply(lambda x: x.replace('[',''))\n",
    "submission['PURCHASED_COUPONS'] = submission['PURCHASED_COUPONS'].apply(lambda x: x.replace(']',''))\n",
    "submission['PURCHASED_COUPONS'] = submission['PURCHASED_COUPONS'].apply(lambda x: x.replace(\"'\",''))\n",
    "submission['PURCHASED_COUPONS'] = submission['PURCHASED_COUPONS'].apply(lambda x: x.replace(',',''))\n",
    "# submission.drop(labels=['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B7. 검증(그래프 같은것들??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B8. submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('test_submission_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import spatial\n",
    "def cosine_similarity(vector_1, vector_2):\n",
    "\n",
    "    return 1 - spatial.distance.cosine(vector_1, vector_2)\n",
    "\n",
    "vector_1 = pd.DataFrame(np.array([[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10],\n",
    "                                 [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10],\n",
    "                                 [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10],[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10],\n",
    "                                 [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10],\n",
    "                                 [1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10]]))\n",
    "vector_2 = pd.DataFrame(np.array([[45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34],\n",
    "                                 [45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34],\n",
    "                                 [45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34],[45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34],\n",
    "                                 [45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34],\n",
    "                                 [45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.6 ms, sys: 1.65 ms, total: 77.3 ms\n",
      "Wall time: 77.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix = []\n",
    "for idx1 in range(len(vector_1)):\n",
    "    row = []\n",
    "    for idx2 in range(len(vector_2)):\n",
    "        row.append(cosine_similarity(vector_1.iloc[idx1], vector_2.iloc[idx2]))\n",
    "    matrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144 * 0.02 / 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24928.81676851852"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7090630 * 22782 * 0.02 / 36 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 ms, sys: 1.76 ms, total: 39.8 ms\n",
      "Wall time: 38.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix = []\n",
    "for idx1 in range(len(vector_1)):\n",
    "    row = []\n",
    "    for idx2 in range(len(vector_2)):\n",
    "        row.append(TS_SS(vector_1.iloc[idx1], vector_2.iloc[idx2]))\n",
    "    matrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247.04655431719746\n",
      "0.7966772313651609\n",
      "27261231.098073907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27261231.098073907"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = np.array([[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],\n",
    "                     [6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10,6,7,8,9,10]]).flatten()\n",
    "vec2 = np.array([[45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44,45,23,56,12,44],\n",
    "                     [34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34,34,34,12,45,34]]).flatten()\n",
    "\n",
    "import math\n",
    "\n",
    "def Cosine(vec1, vec2) :\n",
    "    result = InnerProduct(vec1,vec2) / (VectorSize(vec1) * VectorSize(vec2))\n",
    "    return result\n",
    "\n",
    "def VectorSize(vec) :\n",
    "    return math.sqrt(sum(math.pow(v,2) for v in vec))\n",
    "\n",
    "def InnerProduct(vec1, vec2) :\n",
    "    return sum(v1*v2 for v1,v2 in zip(vec1,vec2))\n",
    "\n",
    "def Euclidean(vec1, vec2) :\n",
    "    return math.sqrt(sum(math.pow((v1-v2),2) for v1,v2 in zip(vec1, vec2)))\n",
    "\n",
    "def Theta(vec1, vec2) :\n",
    "    return math.acos(Cosine(vec1,vec2)) + 10\n",
    "\n",
    "def Triangle(vec1, vec2) :\n",
    "    theta = math.radians(Theta(vec1,vec2))\n",
    "    return (VectorSize(vec1) * VectorSize(vec2) * math.sin(theta)) / 2\n",
    "\n",
    "def Magnitude_Difference(vec1, vec2) :\n",
    "    return abs(VectorSize(vec1) - VectorSize(vec2))\n",
    "\n",
    "def Sector(vec1, vec2) :\n",
    "    ED = Euclidean(vec1, vec2)\n",
    "    MD = Magnitude_Difference(vec1, vec2)\n",
    "    theta = Theta(vec1, vec2)\n",
    "    return math.pi * math.pow((ED+MD),2) * theta/360\n",
    "\n",
    "def TS_SS(vec1, vec2) :\n",
    "    return Triangle(vec1, vec2) * Sector(vec1, vec2)\n",
    "\n",
    "\n",
    "print(Euclidean(vec1,vec2))\n",
    "print(Cosine(vec1,vec2))\n",
    "print(TS_SS(vec1,vec2))\n",
    "\n",
    "\n",
    "\n",
    "TS_SS(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
